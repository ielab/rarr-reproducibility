{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da88502c-bfbb-4b90-ae0d-95d32dc19614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import load_jsonl\n",
    "data = load_jsonl(\"../input/raw/chatGPT.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e8885e-75dd-42b4-a509-e7a5f7c587ae",
   "metadata": {},
   "source": [
    "# build wiki sentence jsonl - each json will have:\n",
    "* \"sid\"\n",
    "* \"pid\"\n",
    "* \"sentence_num\"\n",
    "* \"has_error\"\n",
    "* \"num_facts\"\n",
    "* \"has_annotations\"\n",
    "* \"decon_sentence\"\n",
    "* \"title\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb0fd7d3-1d4a-45f7-93bb-b35fc220f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "level 1 keys: sentence for which there are annotations\n",
    "level 2 keys: 'has_error':\n",
    "              'facts':\n",
    "              'num_facts':\n",
    "              'has_facts'\n",
    "\n",
    "\"\"\"\n",
    "annotated_sentences_dict = {}\n",
    "\n",
    "for i in range(len(data)):\n",
    "    topic = data[i]['topic']\n",
    "    if data[i][\"annotations\"]:\n",
    "        for obj1 in data[i][\"annotations\"]:\n",
    "            sentence = obj1['text']\n",
    "            data_dict = {}\n",
    "            facts = []\n",
    "            labels = []\n",
    "            has_facts = False\n",
    "            if obj1['human-atomic-facts']:\n",
    "                has_facts = True\n",
    "                for obj2 in obj1['human-atomic-facts']:\n",
    "                    facts.append(obj2['text'])\n",
    "                    labels.append(obj2['label'])\n",
    "            data_dict['facts'] = facts\n",
    "            data_dict['num_facts'] = len(facts)\n",
    "            data_dict['has_error'] = 'NS' in labels\n",
    "            data_dict['has_facts'] = has_facts\n",
    "            data_dict['topic'] = topic\n",
    "            annotated_sentences_dict[sentence] = data_dict\n",
    "            \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86b0011c-6700-4fa5-b9de-a828c553f44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1241"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotated_sentences_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ab39d-fd40-4ae4-a45c-e27667912b7e",
   "metadata": {},
   "source": [
    "# create jsonl with desired structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d237d3d-81fa-4e19-8c12-f82a14734e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_jsonl = []\n",
    "sid = 0\n",
    "for pid in range(len(decon_sents)):\n",
    "    for sentence_num, decon_sentence in enumerate(decon_sents[pid][\"decon_sentences\"]):\n",
    "        data_dict = {}\n",
    "        data_dict['pid'] = pid\n",
    "        data_dict['sid'] = sid\n",
    "        data_dict['decon_sentence'] = decon_sentence\n",
    "        sentence = decon_sents[pid][\"sentences\"][sentence_num]\n",
    "        data_dict['sentence'] = sentence\n",
    "        data_dict['sentence_num'] = sentence_num\n",
    "        data_dict['has_error'] = False\n",
    "        data_dict['has_facts'] = False\n",
    "        data_dict['facts'] = []\n",
    "        data_dict['num_facts'] = 0\n",
    "        data_dict['has_annotations'] = False\n",
    "        if sentence in annotated_sentences_dict:\n",
    "            data_dict['has_error'] = annotated_sentences_dict[sentence]['has_error']\n",
    "            data_dict['has_facts'] = annotated_sentences_dict[sentence]['has_facts']\n",
    "            data_dict['facts'] = annotated_sentences_dict[sentence]['facts']\n",
    "            data_dict['num_facts'] = annotated_sentences_dict[sentence]['num_facts']\n",
    "            data_dict['has_annotations'] = True\n",
    "            data_dict['topic'] = annotated_sentences_dict[sentence]['topic']\n",
    "            data_dict['fact_queries'] = [f\"{annotated_sentences_dict[sentence]['topic']}:{fact}\" for fact in data_dict['facts']]\n",
    "    \n",
    "        wiki_jsonl.append(data_dict)\n",
    "        sid += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6954b56a-f3cc-4929-870d-fc467df090a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Write to a .jsonl file\n",
    "with open(\"../input/processed/wiki_input_processed.jsonl\", 'w') as f:\n",
    "    for entry in wiki_jsonl:\n",
    "        f.write(json.dumps(entry) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c2629-97a5-4790-a266-1c604357c4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rarr-rep",
   "language": "python",
   "name": "rarr-rep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
